{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GlobalRefgetStore Tutorial\n",
    "\n",
    "This notebook demonstrates how to use the `GlobalRefgetStore` class from the `gtars.refget` module for managing reference genome sequences using the GA4GH refget standard.\n",
    "\n",
    "## Features Covered\n",
    "\n",
    "1. Creating and populating a local RefgetStore\n",
    "2. Retrieving sequences by ID and collection name\n",
    "3. Getting substrings and BED file regions\n",
    "4. Extracting complete FASTA from a sequence collection\n",
    "5. Saving and loading stores\n",
    "6. Loading remote RefgetStores with lazy loading\n",
    "7. Working with cached remote sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, import the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from gtars.refget import GlobalRefgetStore, StorageMode, digest_fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Local RefgetStore - Full Workflow\n",
    "\n",
    "This section demonstrates the complete workflow for creating and using a local RefgetStore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Create a Sample FASTA File\n",
    "\n",
    "We'll create a temporary FASTA file with two chromosomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory for our example\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "print(f\"Working in temporary directory: {temp_dir}\")\n",
    "\n",
    "# Create a sample FASTA file\n",
    "fasta_content = (\n",
    "    \">chr1\\n\"\n",
    "    \"ATGCATGCATGCAGTCGTAGC\\n\"\n",
    "    \">chr2\\n\"\n",
    "    \"GGGGAAAA\\n\"\n",
    ")\n",
    "source_fasta_path = os.path.join(temp_dir, \"source.fa\")\n",
    "with open(source_fasta_path, \"w\") as f:\n",
    "    f.write(fasta_content)\n",
    "\n",
    "print(f\"Created FASTA file: {source_fasta_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Digest the FASTA to Get Collection Information\n",
    "\n",
    "The `digest_fasta` function computes GA4GH-compliant digests for each sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digest the FASTA to get collection info\n",
    "collection = digest_fasta(source_fasta_path)\n",
    "collection_digest = collection.digest\n",
    "\n",
    "print(f\"Collection digest: {collection_digest}\")\n",
    "print(f\"Number of sequences: {len(collection)}\")\n",
    "print(f\"\\nSequences in collection:\")\n",
    "for seq in collection:\n",
    "    print(f\"  - {seq.metadata.name}: {seq.metadata.sha512t24u}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 1.3 Initialize and Populate a GlobalRefgetStore\n\nCreate a store - you can choose between in-memory or disk-backed:\n- **`in_memory()`**: Keeps all sequences in RAM for fast access (shown below)\n- **`on_disk()`**: Writes sequences to disk immediately, only keeps metadata in RAM (memory-efficient)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Initialize in-memory store in Encoded mode\nstore = GlobalRefgetStore.in_memory(StorageMode.Encoded)\nprint(f\"Initialized store: {store}\")\n\n# Import the FASTA file into the store\nstore.add_sequence_collection_from_fasta(source_fasta_path)\nprint(\"\\nFASTA imported into the store.\")\nprint(f\"Store now contains: {store}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Retrieve Sequences by ID\n",
    "\n",
    "Get a complete sequence using its digest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the digest for chr1\n",
    "seq_digest_chr1 = collection[0].metadata.sha512t24u\n",
    "\n",
    "# Retrieve the sequence record\n",
    "record_chr1 = store.get_sequence_by_id(seq_digest_chr1)\n",
    "\n",
    "if record_chr1:\n",
    "    print(f\"Retrieved sequence: {record_chr1.metadata.name}\")\n",
    "    print(f\"  Length: {record_chr1.metadata.length}\")\n",
    "    print(f\"  Alphabet: {record_chr1.metadata.alphabet}\")\n",
    "    \n",
    "    # Get the full sequence\n",
    "    full_seq = store.get_substring(seq_digest_chr1, 0, record_chr1.metadata.length)\n",
    "    print(f\"  Sequence: {full_seq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Get Substrings\n",
    "\n",
    "Extract specific regions from sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a substring from chr1 (positions 5-15)\n",
    "sub_seq = store.get_substring(seq_digest_chr1, 5, 15)\n",
    "print(f\"Substring chr1[5:15]: {sub_seq}\")\n",
    "\n",
    "# Get a substring from chr2\n",
    "seq_digest_chr2 = collection[1].metadata.sha512t24u\n",
    "sub_seq_chr2 = store.get_substring(seq_digest_chr2, 0, 4)\n",
    "print(f\"Substring chr2[0:4]: {sub_seq_chr2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Retrieve Regions from BED Files\n",
    "\n",
    "Extract multiple regions specified in a BED file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create a BED file with regions of interest\nbed_content = (\n    \"chr1\\t0\\t10\\n\"\n    \"chr2\\t2\\t6\\n\"\n    \"chr_nonexistent\\t0\\t5\\n\"  # This will be skipped\n)\nbed_path = os.path.join(temp_dir, \"regions.bed\")\nwith open(bed_path, \"w\") as f:\n    f.write(bed_content)\n\n# Retrieve sequences as a list\nretrieved_list = store.substrings_from_regions(collection_digest, bed_path)\n\nprint(\"Retrieved sequences from BED file:\")\nfor rs in retrieved_list:\n    print(f\"  {rs.chrom_name}[{rs.start}-{rs.end}]: {rs.sequence}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Write Retrieved Sequences to FASTA\n",
    "\n",
    "Save BED file regions as a new FASTA file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Write retrieved sequences to a FASTA file\noutput_fasta_path = os.path.join(temp_dir, \"output_regions.fa\")\nstore.export_fasta_from_regions(collection_digest, bed_path, output_fasta_path)\n\nprint(f\"Sequences written to: {output_fasta_path}\\n\")\nwith open(output_fasta_path, \"r\") as f:\n    print(\"Content:\")\n    print(f.read())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8 Extract Complete FASTA from a Sequence Collection\n",
    "\n",
    "You can reconstruct the entire FASTA file from a sequence collection by creating a BED file that covers all chromosomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create a BED file covering all sequences in the collection\n# Each line is: chrom_name 0 length (whole chromosome)\nall_seqs_bed = os.path.join(temp_dir, \"all_sequences.bed\")\nwith open(all_seqs_bed, \"w\") as f:\n    for seq in collection:\n        f.write(f\"{seq.metadata.name}\\t0\\t{seq.metadata.length}\\n\")\n\nprint(\"BED file covering all sequences:\")\nwith open(all_seqs_bed, \"r\") as f:\n    print(f.read())\n\n# Extract complete FASTA from the collection\nextracted_fasta_path = os.path.join(temp_dir, \"extracted_complete.fa\")\nstore.export_fasta_from_regions(collection_digest, all_seqs_bed, extracted_fasta_path)\n\nprint(f\"\\nExtracted complete FASTA to: {extracted_fasta_path}\")\nwith open(extracted_fasta_path, \"r\") as f:\n    print(\"\\nContent:\")\n    print(f.read())"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative**: You can also extract sequences programmatically without a BED file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all sequences from a collection programmatically\n",
    "manual_fasta_path = os.path.join(temp_dir, \"manual_extraction.fa\")\n",
    "\n",
    "with open(manual_fasta_path, \"w\") as f:\n",
    "    for seq in collection:\n",
    "        # Get the sequence data\n",
    "        seq_data = store.get_substring(\n",
    "            seq.metadata.sha512t24u,\n",
    "            0,\n",
    "            seq.metadata.length\n",
    "        )\n",
    "        \n",
    "        # Write FASTA header and sequence\n",
    "        f.write(f\">{seq.metadata.name}\\n\")\n",
    "        f.write(f\"{seq_data}\\n\")\n",
    "\n",
    "print(f\"Manually extracted FASTA to: {manual_fasta_path}\")\n",
    "with open(manual_fasta_path, \"r\") as f:\n",
    "    print(\"\\nContent:\")\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9 Save Store to Disk\n",
    "\n",
    "Persist the store for later use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save the store to a directory\nsaved_store_path = os.path.join(temp_dir, \"my_refget_store\")\nstore.write_store_to_dir(saved_store_path, \"sequences/%s2/%s.seq\")\n\nprint(f\"Store saved to: {saved_store_path}\")\nprint(f\"\\nStore structure:\")\nfor root, dirs, files in os.walk(saved_store_path):\n    level = root.replace(saved_store_path, '').count(os.sep)\n    indent = ' ' * 2 * level\n    print(f\"{indent}{os.path.basename(root)}/\")\n    subindent = ' ' * 2 * (level + 1)\n    for file in files:\n        print(f\"{subindent}{file}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.10 Load Store from Disk\n",
    "\n",
    "Load a previously saved store (with lazy loading):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the store using load_local method (with lazy loading)\n",
    "loaded_store = GlobalRefgetStore.load_local(saved_store_path)\n",
    "\n",
    "print(f\"Store loaded from: {saved_store_path}\")\n",
    "print(f\"Loaded store: {loaded_store}\")\n",
    "\n",
    "# Verify we can retrieve sequences (data loaded on-demand)\n",
    "seq = loaded_store.get_substring(seq_digest_chr1, 0, 10)\n",
    "print(f\"\\nRetrieved sequence from loaded store: {seq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Remote RefgetStore with Lazy Loading\n",
    "\n",
    "The `load_remote()` method allows you to work with RefgetStores hosted on remote servers without downloading everything upfront. Sequence data is fetched on-demand and cached locally.\n",
    "\n",
    "### 2.1 Understanding Remote Stores\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Metadata loaded immediately**: Index files (`index.json`, `sequences.farg`) are fetched from remote\n",
    "- **Sequence data loaded on-demand**: Actual `.seq` files are only downloaded when accessed\n",
    "- **Local caching**: Downloaded sequences are cached to avoid re-fetching\n",
    "- **User-controlled cache**: You specify where cached data is stored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Simulating a Remote Store\n",
    "\n",
    "For this example, we'll use the store we created earlier and treat it as a \"remote\" store using a `file://` URL. In practice, you'd use `http://` or `https://` URLs pointing to an actual remote server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cache directory for remote data\n",
    "cache_dir = os.path.join(temp_dir, \"refget_cache\")\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Cache directory: {cache_dir}\")\n",
    "\n",
    "# Simulate a remote URL (in practice, this would be https://...)\n",
    "remote_url = f\"file://{saved_store_path}\"\n",
    "print(f\"Remote URL: {remote_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Load Remote Store\n",
    "\n",
    "Load a store from a remote URL with local caching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load remote store\n",
    "# In a real scenario, remote_url would be something like:\n",
    "# \"https://s3.amazonaws.com/genomes/hg38\" or \"https://refget.example.com/store\"\n",
    "remote_store = GlobalRefgetStore.load_remote(cache_dir, remote_url)\n",
    "\n",
    "print(f\"Remote store loaded: {remote_store}\")\n",
    "print(f\"\\nCache directory contents (metadata only at this point):\")\n",
    "for root, dirs, files in os.walk(cache_dir):\n",
    "    for file in files:\n",
    "        rel_path = os.path.relpath(os.path.join(root, file), cache_dir)\n",
    "        print(f\"  - {rel_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Access Sequences (Triggers Lazy Loading)\n",
    "\n",
    "When you request a sequence, it's automatically fetched and cached:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First access - triggers download and caching\n",
    "print(\"First access (will fetch from remote and cache):\")\n",
    "seq1 = remote_store.get_substring(seq_digest_chr1, 0, 10)\n",
    "print(f\"  Sequence: {seq1}\")\n",
    "\n",
    "print(f\"\\nCache directory contents (after first access):\")\n",
    "for root, dirs, files in os.walk(cache_dir):\n",
    "    for file in files:\n",
    "        rel_path = os.path.relpath(os.path.join(root, file), cache_dir)\n",
    "        file_size = os.path.getsize(os.path.join(root, file))\n",
    "        print(f\"  - {rel_path} ({file_size} bytes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second access - uses cached data (no network request)\n",
    "print(\"\\nSecond access (uses cache, no network request):\")\n",
    "seq2 = remote_store.get_substring(seq_digest_chr1, 5, 15)\n",
    "print(f\"  Sequence: {seq2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Real-World Example Template\n",
    "\n",
    "Here's how you would use this with an actual remote RefgetStore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Loading a remote genome (pseudocode - URL would need to be real)\n",
    "'''\n",
    "# Load human genome hg38 from a remote server\n",
    "cache_path = \"/data/refget_cache/hg38\"\n",
    "remote_url = \"https://refget-server.example.com/hg38\"\n",
    "\n",
    "hg38_store = GlobalRefgetStore.load_remote(cache_path, remote_url)\n",
    "\n",
    "# Get chr1 sequence (only chr1 data is downloaded and cached)\n",
    "chr1_digest = \"...\"\n",
    "sequence = hg38_store.get_substring(chr1_digest, 1000000, 1001000)\n",
    "\n",
    "# Subsequent accesses use the cached chr1 data\n",
    "another_region = hg38_store.get_substring(chr1_digest, 2000000, 2001000)\n",
    "'''\n",
    "print(\"See code cell for real-world usage example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Part 3: Comparison - Local vs Remote Loading\n\n### When to Use Each Method\n\n| Method | Use Case | Pros | Cons |\n|--------|----------|------|------|\n| `load_local(path)` | Store is already on disk | Fast, no network | Requires full download |\n| `load_remote(cache, url)` | Store hosted remotely | Only download what you need | Slower first access |\n\n### Performance Characteristics\n\n**Local Store:**\n- Initial load: Fast (metadata only)\n- First sequence access: Fast (local disk)\n- Subsequent access: Fast (cached in memory)\n\n**Remote Store:**\n- Initial load: 2 HTTP requests (index.json, sequences.farg)\n- First sequence access: 1 HTTP request + cache write\n- Subsequent access: Fast (cached on disk)\n\n### Benefits of Lazy Loading\n\n1. **Memory efficient**: Only loaded sequences consume memory\n2. **Bandwidth efficient**: Only download what you use\n3. **Fast startup**: No waiting for full genome download\n4. **Selective caching**: Control which sequences to cache locally"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Remove temporary files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Clean up temporary directory\n",
    "shutil.rmtree(temp_dir)\n",
    "print(f\"Cleaned up temporary directory: {temp_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. ✅ Creating and populating a RefgetStore from FASTA files\n",
    "2. ✅ Retrieving sequences by digest and collection name\n",
    "3. ✅ Extracting substrings and BED file regions\n",
    "4. ✅ Extracting complete FASTA files from sequence collections\n",
    "5. ✅ Saving stores to disk and loading them back\n",
    "6. ✅ Loading remote RefgetStores with lazy loading\n",
    "7. ✅ On-demand sequence fetching with local caching\n",
    "\n",
    "For more information, see the [gtars documentation](https://github.com/databio/gtars)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}