{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66137bf9-4f78-4b89-aa64-6734400df15e",
   "metadata": {},
   "source": [
    "# How to build a new universe?\n",
    "\n",
    "## Data preprocessing\n",
    "This is a jupyter version of CLI tutorial that can be found [here](../tutorials/create-consensus-peaks.md). You will use here python functions instead of CLI to build and assess different universes. Files that you will use here can be downloaded from XXX. In there you will find a compressed folder:\n",
    "\n",
    "```\n",
    "consensus:\n",
    "    - raw\n",
    "        test_1.bed\n",
    "        test_2.bed\n",
    "        test_3.bed\n",
    "        test_4.bed\n",
    "    file_list.txt\n",
    "    chrom.sizes\n",
    "```\n",
    "\n",
    "In the raw folder there are example BED files used in this tutorial and in file_list.txt are names of files you will analyze. Additionally there is a file with chromosome sizes, which you will use to preprocess the data. \n",
    "\n",
    "Here we assume that you already have files of the genome coverage by the analyzed collection. The example of how to create them can be found [here](../tutorials/create-consensus-peaks.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bc1fc3-0c43-43af-908e-0798afbbe459",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Coverage cutoff universe\n",
    "\n",
    "First, you will create a coverage cutoff universe (CC). This is the simplest type of a universe that only includes genomic positions with coverage greater or equal to cutoff *x*. This cutoff by default is calculated using simple likelihood model that calculates the probability of appearing in a collection. The universe can be build just based on genome coverage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "141886ce-3d97-4edb-8a9b-bdd5dff53bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geniml.universe.cc_universe import cc_universe\n",
    "cc_universe(\"coverage/\", file_out=\"universe_cc.bed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56af8029-97b1-4bd6-81a9-af86a6b6c83e",
   "metadata": {},
   "source": [
    "Depending on the task the universe can be smooth by setting ```merge``` option with the distance below witch peaks should be merged together and \n",
    "`filter_size` with minimum size of peak that should be part of the universe. Instead of using maximum likelihood cutoff one can also defined cutoff with `cutoff` option. If it is set to 1 the result is union universe, and when to number of files it wil produce intersection universe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e1c433d-e2f4-4fdd-9377-1d417f64102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_universe(\"coverage/\", file_out=\"universe_union.bed\", cutoff=1)\n",
    "cc_universe(\"coverage/\", file_out=\"universe_intersection.bed\", cutoff=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d63171-4784-433d-a3d2-875c2ecd7be3",
   "metadata": {},
   "source": [
    "## Coverage cutoff flexible universe\n",
    "A more complex version of coverage cutoff universe is coverage cutoff flexible universe (CCF). In contrast to its' fixed version it produces flexible universes. It uses two cutoffs calculated based on maximum likelihood cutoff, making a confidence interval around the optimal cutoff value. Despite the fact that the CFF universe is more complex it is build using the same input as the CC universe: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f431b2a-49e9-4ad5-8fcf-d77fa343e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geniml.universe.ccf_universe import ccf_universe\n",
    "\n",
    "ccf_universe(\"coverage/\", file_out=\"universe_ccf.bed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a7b97d-b2ac-449d-b162-5b71b15ab358",
   "metadata": {},
   "source": [
    "## Maximum likelihood universe\n",
    "In the previous examples both CC anf CCF universes used simple likelihood model to calculate the cutoff. However, we also developed more complex likelihood model that takes into account the positions of starts and ends of the regions in the collection. This LH model can build based on coverage files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d1cd9be-9ba8-42a3-8543-bfbc1fcfa153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function 'main' executed in 0.0001min\n"
     ]
    }
   ],
   "source": [
    "from geniml.likelihood.build_model import main\n",
    "\n",
    "main(\"model.tar\", \"coverage/\",\n",
    "     \"all\",\n",
    "     file_no=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05ebdb6-cf66-4b0c-abbd-2fc75f093350",
   "metadata": {},
   "source": [
    "The resulting tar archiver contains LH model. This model can be used as a scoring function that assigns to each position probability of it being a start, core or end of a region. It can be both used for universe assessment and universe building. Combination of LH model and optimization algorithm for building flexible universes results in maximum likelihood universe (ML):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d50948d0-f46b-4eb0-a2ab-9121f315ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geniml.universe.ml_universe import ml_universe\n",
    "\n",
    "ml_universe(\"model.tar\",\n",
    "     \"coverage\",\n",
    "     \"all\",\n",
    "     \"universe_ml.bed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220c0272-4c83-43b0-83a2-93cd7f3292a9",
   "metadata": {},
   "source": [
    "## HMM \n",
    "The forth presented method of creating universes utilizes Hidden Markov Models. In this approach the parts of flexible regions are hidden states of the model, while genome coverage by the collections are emissions. The resulting universe is called Hidden Markov Model universe. It can be build only based on the genome coverage by the collection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bc3ea52-25cc-4d62-8727-12ea9f928c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from geniml.universe.hmm_universe import hmm_universe\n",
    "\n",
    "hmm_universe(\"coverage/\",\n",
    "             \"universe_hmm.bed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab159ce-aa6f-4b56-9696-59f7db7c81b2",
   "metadata": {},
   "source": [
    "# How to assess new universe?\n",
    "\n",
    "So far you used many different methods for creating new universes. But choosing, which universe represents data the best can be challenging. To help with this decision we created three different metrics for assessing universe fit to the region collections: a base-level overlap score (F10), a region boundary distance score (RBD), and a likelihood score (LH). Here we present an example, which calculates all these metrics for HMM universe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b36ce9d-5412-4ba8-afe7-964909806e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Universe F10: 0.93'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from geniml.assess.assess import get_f_10_score\n",
    "\n",
    "f10 = get_f_10_score(\n",
    "    \"raw/\",\n",
    "    'file_list.txt',\n",
    "    \"universe_hmm.bed\",\n",
    "    1)\n",
    "\n",
    "f\"Universe F10: {f10:.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b29421c-8543-4fc9-ac83-ad6f7d0f70df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Universe RBS: 0.77'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from geniml.assess.assess import get_mean_rbs\n",
    "rbs = get_mean_rbs(\"raw/\",\n",
    "    'file_list.txt',\n",
    "    \"universe_hmm.bed\", 1)\n",
    "f\"Universe RBS: {rbs:.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "711fbb4f-4502-499e-8b5d-e879e26a0124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Universe LH: -127156.87'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from geniml.assess.assess import get_likelihood\n",
    "lh = get_likelihood(\n",
    "    \"model.tar\",\n",
    "    \"universe_hmm.bed\",\n",
    "    \"coverage/\"\n",
    ")\n",
    "f\"Universe LH: {lh:.2f}\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171e1240-e12a-450a-9df9-ad1f0d97e398",
   "metadata": {},
   "source": [
    "Both region boundary score and likelihood can be also calculated taking into account universe flexibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa597da1-d452-4583-973d-92263512b38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Universe flexible RBS: 0.98'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from geniml.assess.assess import get_mean_rbs\n",
    "rbs_flex = get_mean_rbs(\n",
    "    \"raw/\",\n",
    "    'file_list.txt',\n",
    "    \"universe_hmm.bed\",\n",
    "    1,\n",
    "    flexible=True)\n",
    "f\"Universe flexible RBS: {rbs_flex:.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "315a1dce-e045-41a0-b1ed-e06d117bebaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Universe flexible LH: -127156.87'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lh_flex = get_likelihood(\n",
    "    \"model.tar\",\n",
    "    \"universe_hmm.bed\",\n",
    "    \"coverage/\"\n",
    ")\n",
    "f\"Universe flexible LH: {lh_flex:.2f}\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece5e3df-647f-46ab-bd95-4add00ebdfd5",
   "metadata": {},
   "source": [
    "In CLI version of this [tutorial](../tutorials/create-consensus-peaks.md) it was shown how to calculate an assessment file with all the metrics. This file can be further summarized into specific metrics assessing the fit of a universe to a whole collection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "462ffa69-3867-42b3-84f9-0cbe394dbd20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>univers/file</th>\n",
       "      <th>file/universe</th>\n",
       "      <th>universe&amp;file</th>\n",
       "      <th>median_dist_file_to_universe</th>\n",
       "      <th>median_dist_file_to_universe_flex</th>\n",
       "      <th>median_dist_universe_to_file</th>\n",
       "      <th>median_dist_universe_to_file_flex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_1.bed</td>\n",
       "      <td>2506</td>\n",
       "      <td>403</td>\n",
       "      <td>3630</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_2.bed</td>\n",
       "      <td>1803</td>\n",
       "      <td>146</td>\n",
       "      <td>4333</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_3.bed</td>\n",
       "      <td>2949</td>\n",
       "      <td>0</td>\n",
       "      <td>3187</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>224.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_4.bed</td>\n",
       "      <td>2071</td>\n",
       "      <td>546</td>\n",
       "      <td>4065</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>116.5</td>\n",
       "      <td>105.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         file  univers/file  file/universe  universe&file  \\\n",
       "0  test_1.bed          2506            403           3630   \n",
       "1  test_2.bed          1803            146           4333   \n",
       "2  test_3.bed          2949              0           3187   \n",
       "3  test_4.bed          2071            546           4065   \n",
       "\n",
       "   median_dist_file_to_universe  median_dist_file_to_universe_flex  \\\n",
       "0                          27.0                                0.0   \n",
       "1                          27.0                                0.0   \n",
       "2                          28.0                                0.0   \n",
       "3                          27.0                                0.0   \n",
       "\n",
       "   median_dist_universe_to_file  median_dist_universe_to_file_flex  \n",
       "0                          76.5                                0.0  \n",
       "1                          70.0                                7.5  \n",
       "2                         225.0                              224.5  \n",
       "3                         116.5                              105.5  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from geniml.assess.assess import get_rbs_from_assessment_file, get_f_10_score_from_assessment_file\n",
    "import pandas as pd\n",
    "\n",
    "assessment_file_path = \"test_assess_data.csv\"\n",
    "df = pd.read_csv(assessment_file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f9f3a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Universe \n",
      "F10: 0.93\n",
      "RBS: 0.77\n",
      "flexible RBS: 0.98\n"
     ]
    }
   ],
   "source": [
    "rbs = get_rbs_from_assessment_file(assessment_file_path)\n",
    "f_10 = get_f_10_score_from_assessment_file(assessment_file_path)\n",
    "rbs_flex = get_rbs_from_assessment_file(assessment_file_path, flexible=True)\n",
    "print(f\"Universe \\nF10: {f_10:.2f}\\nRBS: {rbs:.2f}\\nflexible RBS: {rbs_flex:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76201732-509f-46ca-a703-ec804a03e097",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
