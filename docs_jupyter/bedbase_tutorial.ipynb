{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEDBASE workflow tutorial\n",
    "\n",
    "This demo demonstrates how to process, analyze, visualize, and serve BED files. The process has 3 steps: First, individual BED files are analyzed using the [bedstat](https://github.com/databio/bedstat) pipeline. Second, BED files are grouped and then analyzed as groups using the [bedbuncher](https://github.com/databio/bedbuncher) pipeline. Finally, the BED files, along with statistics, plots, and grouping information, is served via a web interface and RESTful API using the [bedhost](https://github.com/databio/bedhost/tree/master) package.\n",
    "\n",
    "**Glossary of terms:**\n",
    "\n",
    "- *bedfile*: a tab-delimited file with one genomic region per line. Each genomic region is decribed by 3 required columns: chrom, start and end.\n",
    "- *bedset*: a collection of BED files grouped by with a shared biological, experimental, or logical criterion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1.-Preparation\" data-toc-modified-id=\"1.-Preparation-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>1. Preparation</a></span></li><li><span><a href=\"#2.-BEDSTAT:-Generate-statistics-and-plots-of-BED-files\" data-toc-modified-id=\"2.-BEDSTAT:-Generate-statistics-and-plots-of-BED-files-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>2. BEDSTAT: Generate statistics and plots of BED files</a></span><ul class=\"toc-item\"><li><span><a href=\"#Get-a-PEP-describing-the-bedfiles-to-process\" data-toc-modified-id=\"Get-a-PEP-describing-the-bedfiles-to-process-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Get a PEP describing the bedfiles to process</a></span></li><li><span><a href=\"#Install-bedstat-dependencies\" data-toc-modified-id=\"Install-bedstat-dependencies-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Install bedstat dependencies</a></span></li><li><span><a href=\"#Inititiate-a-local-elasticsearch-cluster\" data-toc-modified-id=\"Inititiate-a-local-elasticsearch-cluster-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Inititiate a local elasticsearch cluster</a></span></li><li><span><a href=\"#Run-bedstat--on-the-demo-PEP\" data-toc-modified-id=\"Run-bedstat--on-the-demo-PEP-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Run bedstat  on the demo PEP</a></span></li></ul></li><li><span><a href=\"#3.-BEDBUNCHER:-Create-bedsets-and-their-respective-statistics\" data-toc-modified-id=\"3.-BEDBUNCHER:-Create-bedsets-and-their-respective-statistics-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>3. BEDBUNCHER: Create bedsets and their respective statistics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Create-a-new-PEP-describing-the-bedset-name-and-specific-JSON-query\" data-toc-modified-id=\"Create-a-new-PEP-describing-the-bedset-name-and-specific-JSON-query-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Create a new PEP describing the bedset name and specific JSON query</a></span></li><li><span><a href=\"#Create-outputs-directory-and-install-bedbuncher-CML-dependencies\" data-toc-modified-id=\"Create-outputs-directory-and-install-bedbuncher-CML-dependencies-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Create outputs directory and install bedbuncher CML dependencies</a></span></li><li><span><a href=\"#Run-bedbuncher-using-Looper\" data-toc-modified-id=\"Run-bedbuncher-using-Looper-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Run bedbuncher using Looper</a></span></li></ul></li><li><span><a href=\"#4.-BEDHOST:--Serve-BED-files-and-API-to-explore-pipeline-outputs\" data-toc-modified-id=\"4.-BEDHOST:--Serve-BED-files-and-API-to-explore-pipeline-outputs-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>4. BEDHOST:  Serve BED files and API to explore pipeline outputs</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparation \n",
    "\n",
    "First, we will create a tutorial directory where we'll store the bedbase pipelines and files to be processed. We'll also need to create an environment variable that points to the tutorial directory (we'll need this variable later). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir bedbase_tutorial\n",
    "cd bedbase_tutorial\n",
    "export BBTUTORIAL=`pwd`\n",
    "export BEDBASE_DATA_PATH_HOST=`pwd`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download some example BED files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-11 12:06:50--  http://big.databio.org/example_data/bedbase_tutorial/bed_files.tar.gz\n",
      "Resolving big.databio.org (big.databio.org)... 128.143.245.181, 128.143.245.182\n",
      "Connecting to big.databio.org (big.databio.org)|128.143.245.181|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 44549692 (42M) [application/octet-stream]\n",
      "Saving to: ‘bed_files.tar.gz’\n",
      "\n",
      "bed_files.tar.gz    100%[===================>]  42.49M  2.56MB/s    in 16s     \n",
      "\n",
      "2021-11-11 12:07:07 (2.60 MB/s) - ‘bed_files.tar.gz’ saved [44549692/44549692]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wget http://big.databio.org/example_data/bedbase_tutorial/bed_files.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The downloaded files are compressed so we'll need to untar them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bed_files/\n",
      "bed_files/GSE105587_ENCFF018NNF_conservative_idr_thresholded_peaks_GRCh38.bed.gz\n",
      "bed_files/GSM2423312_ENCFF155HVK_peaks_GRCh38.bed.gz\n",
      "bed_files/GSE105977_ENCFF617QGK_optimal_idr_thresholded_peaks_GRCh38.bed.gz\n",
      "bed_files/GSE91663_ENCFF316ASR_peaks_GRCh38.bed.gz\n",
      "bed_files/GSM2423313_ENCFF722AOG_peaks_GRCh38.bed.gz\n",
      "bed_files/GSM2827349_ENCFF196DNQ_peaks_GRCh38.bed.gz\n",
      "bed_files/GSE91663_ENCFF553KIK_optimal_idr_thresholded_peaks_GRCh38.bed.gz\n",
      "bed_files/GSE91663_ENCFF319TPR_conservative_idr_thresholded_peaks_GRCh38.bed.gz\n",
      "bed_files/GSE105977_ENCFF937CGY_peaks_GRCh38.bed.gz\n",
      "bed_files/GSM2827350_ENCFF928JXU_peaks_GRCh38.bed.gz\n",
      "bed_files/GSE105977_ENCFF793SZW_conservative_idr_thresholded_peaks_GRCh38.bed.gz\n"
     ]
    }
   ],
   "source": [
    "tar -zxvf bed_files.tar.gz\n",
    "rm -rf bed_files.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we'll download a matrix we need to provide if we wish to plot the tissue specificity of our set of genomic ranges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-11 12:08:49--  http://big.databio.org/open_chromatin_matrix/openSignalMatrix_hg38_percentile99_01_quantNormalized_round4d.txt.gz\n",
      "Resolving big.databio.org (big.databio.org)... 128.143.245.181, 128.143.245.182\n",
      "Connecting to big.databio.org (big.databio.org)|128.143.245.181|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 380989260 (363M) [application/octet-stream]\n",
      "Saving to: ‘openSignalMatrix_hg38_percentile99_01_quantNormalized_round4d.txt.gz’\n",
      "\n",
      "openSignalMatrix_hg 100%[===================>] 363.34M  1.93MB/s    in 2m 16s  \n",
      "\n",
      "2021-11-11 12:11:05 (2.68 MB/s) - ‘openSignalMatrix_hg38_percentile99_01_quantNormalized_round4d.txt.gz’ saved [380989260/380989260]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wget http://big.databio.org/open_chromatin_matrix/openSignalMatrix_hg38_percentile99_01_quantNormalized_round4d.txt.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we'll download the core pipelines and tools needed to complete this tutorial: `bedstat`, `bedbuncher` , `bedhost`, and `bedhost-ui`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'bedbase'...\n",
      "remote: Enumerating objects: 384, done.\u001b[K\n",
      "remote: Counting objects: 100% (384/384), done.\u001b[K\n",
      "remote: Compressing objects: 100% (244/244), done.\u001b[K\n",
      "remote: Total 384 (delta 182), reused 284 (delta 102), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (384/384), 546.27 KiB | 767.00 KiB/s, done.\n",
      "Resolving deltas: 100% (182/182), done.\n",
      "Cloning into 'bedstat'...\n",
      "remote: Enumerating objects: 750, done.\u001b[K\n",
      "remote: Counting objects: 100% (260/260), done.\u001b[K\n",
      "remote: Compressing objects: 100% (103/103), done.\u001b[K\n",
      "remote: Total 750 (delta 120), reused 221 (delta 98), pack-reused 490\u001b[K\n",
      "Receiving objects: 100% (750/750), 165.38 KiB | 7.52 MiB/s, done.\n",
      "Resolving deltas: 100% (351/351), done.\n",
      "Cloning into 'bedbuncher'...\n",
      "remote: Enumerating objects: 611, done.\u001b[K\n",
      "remote: Counting objects: 100% (143/143), done.\u001b[K\n",
      "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
      "remote: Total 611 (delta 66), reused 105 (delta 37), pack-reused 468\u001b[K\n",
      "Receiving objects: 100% (611/611), 113.48 KiB | 5.97 MiB/s, done.\n",
      "Resolving deltas: 100% (319/319), done.\n",
      "Cloning into 'bedhost'...\n",
      "remote: Enumerating objects: 1920, done.\u001b[K\n",
      "remote: Counting objects: 100% (109/109), done.\u001b[K\n",
      "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
      "remote: Total 1920 (delta 49), reused 37 (delta 14), pack-reused 1811\u001b[K\n",
      "Receiving objects: 100% (1920/1920), 453.61 KiB | 7.20 MiB/s, done.\n",
      "Resolving deltas: 100% (1181/1181), done.\n",
      "Cloning into 'bedhost-ui'...\n",
      "remote: Enumerating objects: 1462, done.\u001b[K\n",
      "remote: Counting objects: 100% (825/825), done.\u001b[K\n",
      "remote: Compressing objects: 100% (298/298), done.\u001b[K\n",
      "remote: Total 1462 (delta 595), reused 732 (delta 526), pack-reused 637\u001b[K\n",
      "Receiving objects: 100% (1462/1462), 761.58 KiB | 2.27 MiB/s, done.\n",
      "Resolving deltas: 100% (1092/1092), done.\n"
     ]
    }
   ],
   "source": [
    "git clone -b master git@github.com:Khoroshevskyi/bedbase.git\n",
    "git clone -b validate_genome_assembly git@github.com:databio/bedstat.git\n",
    "git clone -b validate_genome_assembly git@github.com:databio/bedbuncher\n",
    "git clone -b dev git@github.com:databio/bedhost\n",
    "git clone -b dev git@github.com:databio/bedhost-ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. BEDSTAT: Generate statistics and plots of BED files \n",
    "\n",
    "### Get a PEP describing the bedfiles to process\n",
    "\n",
    "The first step is to process the BED files using the `bedstat` pipeline, which computes statistics and makes plots for each individual BED file. To begin, we'll need some annotation information for our BED files to load. We'll use the standard [PEP](https://pepkit.github.io/) format for the annotation, which consists of 1) a sample table (.csv) that annotates the files, and 2) a project config.yaml file that points to the sample annotation sheet. The config file also has other components, such as derived attributes, that in this case point to the bedfiles to be processed. Here is the PEP config file for this example project. It includes annotation information for each BED file, and also points to the `.bed.gz` files using derived attributes `output_file_path` and `yaml_file`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pep_version: 2.0.0\n",
      "sample_table: bedstat_annotation_sheet.csv\n",
      "\n",
      "looper:\n",
      "    output-dir: $BEDBASE_DATA_PATH_HOST/outputs/bedstat_output/bedstat_pipeline_logs\n",
      "\n",
      "sample_modifiers:\n",
      "  append:\n",
      "    bedbase_config: $BEDBASE_DATA_PATH_HOST/bedbase/tutorial_files/bedbase_configuration_compose.yaml\n",
      "    pipeline_interfaces: $BEDBASE_DATA_PATH_HOST/bedstat/pipeline_interface.yaml\n",
      "    output_file_path: OUTPUT\n",
      "    yaml_file: SAMPLE_YAML\n",
      "    open_signal_matrix: MATRIX\n",
      "    bigbed:  BIGBED\n",
      "  derive:\n",
      "    attributes: [output_file_path, yaml_file, open_signal_matrix, bigbed]\n",
      "    sources:\n",
      "      OUTPUT: \"$BEDBASE_DATA_PATH_HOST/bed_files/{file_name}\"\n",
      "      SAMPLE_YAML: \"$BEDBASE_DATA_PATH_HOST/outputs/bedstat_output/bedstat_pipeline_logs/submission/{sample_name}_sample.yaml\"\n",
      "      MATRIX: \"$BEDBASE_DATA_PATH_HOST/openSignalMatrix_{genome}_percentile99_01_quantNormalized_round4d.txt.gz\"\n",
      "      BIGBED: \"$BEDBASE_DATA_PATH_HOST/bigbed_files\"\n"
     ]
    }
   ],
   "source": [
    "cat bedbase/tutorial_files/PEPs/bedstat_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install bedstat dependencies\n",
    "\n",
    "`bedstat` is a [pypiper](http://code.databio.org/pypiper/) pipeline that generates statistics and plots of bedfiles. Additionally, `bedstat` uses [bbconf](https://github.com/databio/bbconf), the bedbase configuration manager which implements convenience methods for interacting with an Elasticsearch database, where our file metadata will be placed. These and the appropriate R dependencies can be installed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r bedstat/requirements/requirements-all.txt  --user > requirements_log.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install R dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading required package: R.utils\n",
      "Loading required package: R.oo\n",
      "Loading required package: R.methodsS3\n",
      "R.methodsS3 v1.8.1 (2020-08-26 16:20:06 UTC) successfully loaded. See ?R.methodsS3 for help.\n",
      "R.oo v1.24.0 (2020-08-26 16:11:58 UTC) successfully loaded. See ?R.oo for help.\n",
      "\n",
      "Attaching package: ‘R.oo’\n",
      "\n",
      "The following object is masked from ‘package:R.methodsS3’:\n",
      "\n",
      "    throw\n",
      "\n",
      "The following objects are masked from ‘package:methods’:\n",
      "\n",
      "    getClasses, getMethods\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    attach, detach, load, save\n",
      "\n",
      "R.utils v2.11.0 (2021-09-26 08:30:02 UTC) successfully loaded. See ?R.utils for help.\n",
      "\n",
      "Attaching package: ‘R.utils’\n",
      "\n",
      "The following object is masked from ‘package:utils’:\n",
      "\n",
      "    timestamp\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    cat, commandArgs, getOption, inherits, isOpen, nullfile, parse,\n",
      "    warnings\n",
      "\n",
      "Loading required package: BiocManager\n",
      "Bioconductor version '3.13' is out-of-date; the current release version '3.14'\n",
      "  is available with R version '4.1'; see https://bioconductor.org/install\n",
      "Loading required package: optparse\n",
      "Loading required package: devtools\n",
      "Loading required package: usethis\n",
      "\n",
      "Attaching package: ‘devtools’\n",
      "\n",
      "The following object is masked from ‘package:BiocManager’:\n",
      "\n",
      "    install\n",
      "\n",
      "The following objects are masked from ‘package:R.oo’:\n",
      "\n",
      "    check, unload\n",
      "\n",
      "Loading required package: GenomicRanges\n",
      "Loading required package: stats4\n",
      "Loading required package: BiocGenerics\n",
      "Loading required package: parallel\n",
      "\n",
      "Attaching package: ‘BiocGenerics’\n",
      "\n",
      "The following objects are masked from ‘package:parallel’:\n",
      "\n",
      "    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,\n",
      "    clusterExport, clusterMap, parApply, parCapply, parLapply,\n",
      "    parLapplyLB, parRapply, parSapply, parSapplyLB\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    IQR, mad, sd, var, xtabs\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    anyDuplicated, append, as.data.frame, basename, cbind, colnames,\n",
      "    dirname, do.call, duplicated, eval, evalq, Filter, Find, get, grep,\n",
      "    grepl, intersect, is.unsorted, lapply, Map, mapply, match, mget,\n",
      "    order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank,\n",
      "    rbind, Reduce, rownames, sapply, setdiff, sort, table, tapply,\n",
      "    union, unique, unsplit, which.max, which.min\n",
      "\n",
      "Loading required package: S4Vectors\n",
      "\n",
      "Attaching package: ‘S4Vectors’\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    expand.grid, I, unname\n",
      "\n",
      "Loading required package: IRanges\n",
      "\n",
      "Attaching package: ‘IRanges’\n",
      "\n",
      "The following object is masked from ‘package:R.oo’:\n",
      "\n",
      "    trim\n",
      "\n",
      "Loading required package: GenomeInfoDb\n",
      "Loading required package: GenomicFeatures\n",
      "Loading required package: AnnotationDbi\n",
      "Loading required package: Biobase\n",
      "Welcome to Bioconductor\n",
      "\n",
      "    Vignettes contain introductory material; view with\n",
      "    'browseVignettes()'. To cite Bioconductor, see\n",
      "    'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'.\n",
      "\n",
      "Loading required package: ensembldb\n",
      "Loading required package: AnnotationFilter\n",
      "\n",
      "Attaching package: 'ensembldb'\n",
      "\n",
      "The following object is masked from 'package:stats':\n",
      "\n",
      "    filter\n",
      "\n",
      "Loading required package: LOLA\n",
      "Loading required package: BSgenome\n",
      "Loading required package: Biostrings\n",
      "Loading required package: XVector\n",
      "\n",
      "Attaching package: 'Biostrings'\n",
      "\n",
      "The following object is masked from 'package:base':\n",
      "\n",
      "    strsplit\n",
      "\n",
      "Loading required package: rtracklayer\n",
      "Loading required package: GenomicDistributions\n",
      "Loading required package: GenomicDistributionsData\n",
      "snapshotDate(): 2021-05-18\n"
     ]
    }
   ],
   "source": [
    "Rscript bedstat/scripts/installRdeps.R > R_deps.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's an additional dependency needed by `bedstat` if we wish to calculate and plot the GC content of our bedfiles. Depending on the genome assemblies of the files listed on a PEP, the appropriate BSgenome packages should be installed. The following is an example of how we can do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if (!requireNamespace(\"BiocManager\", quietly = TRUE))\n",
      "    install.packages(\"BiocManager\")\n",
      "\n",
      "BiocManager::install(\"BSgenome.Hsapiens.UCSC.hg38.masked\")"
     ]
    }
   ],
   "source": [
    "cat bedbase/tutorial_files/scripts/BSgenome_install.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'getOption(\"repos\")' replaces Bioconductor standard repositories, see\n",
      "'?repositories' for details\n",
      "\n",
      "replacement repositories:\n",
      "    CRAN: https://cloud.r-project.org\n",
      "\n",
      "Bioconductor version 3.13 (BiocManager 1.30.16), R 4.1.1 (2021-08-10)\n",
      "Installation paths not writeable, unable to update packages\n",
      "  path: /usr/lib/R/library\n",
      "  packages:\n",
      "    nlme, spatial\n",
      "Old packages: 'GenomicDistributionsData', 'gert', 'readr'\n",
      "Warning message:\n",
      "package(s) not installed when version(s) same as current; use `force = TRUE` to\n",
      "  re-install: 'BSgenome.Hsapiens.UCSC.hg38.masked' \n"
     ]
    }
   ],
   "source": [
    "Rscript bedbase/tutorial_files/scripts/BSgenome_install.R > BSgenome.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to create a directory where we can store the stats and plots generated by `bedstat`. Additionally, we'll create a directory where we can store log and metadata files that we'll need later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p outputs/bedstat_output/bedstat_pipeline_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use `bbconf`, we'll need to create a minimal configuration.yaml file. The path to this configuration file can be stored in the environment variable `$BEDBASE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path:\n",
      "  pipeline_output_path: $BEDBASE_DATA_PATH_HOST/outputs\n",
      "  bedstat_dir: bedstat_output\n",
      "  bedbuncher_dir: bedbuncher_output\n",
      "  remote_url_base: null\n",
      "database:\n",
      "  host: $DB_HOST_URL\n",
      "  port: $POSTGRES_PORT\n",
      "  password: $POSTGRES_PASSWORD\n",
      "  user: $POSTGRES_USER\n",
      "  name: $POSTGRES_DB\n",
      "  dialect: postgresql\n",
      "  driver: psycopg2\n",
      "server:\n",
      "  host: 0.0.0.0\n",
      "  port: 8000\n"
     ]
    }
   ],
   "source": [
    "cat bedbase/tutorial_files/bedbase_configuration_compose.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inititiate a local PostgreSQL instance\n",
    "\n",
    "In addition to generate statistics and plots, `bedstat` inserts JSON formatted metadata into relational [PostgreSQL] database. \n",
    "\n",
    "If you don't have docker installed, you can install it with `sudo apt-get update && apt-get install docker-engine -y`. You can find full instalation here: https://docs.docker.com/get-docker/\n",
    "\n",
    "Now, create a persistent volume to house PostgreSQL data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postgres-data\n"
     ]
    }
   ],
   "source": [
    "docker volume create postgres-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spin up a `postgres` container. Provide required environment variables (need to match the settings in bedbase configuration file) and bind the created docker volume to `/var/lib/postgresql/data` path in the container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64fdf61f5062e69660fe39fdbda0c9e6984e5408baf78457c0b3d172e50f8a7d\n"
     ]
    }
   ],
   "source": [
    "docker run -d --name bedbase-postgres -p 5432:5432 -e POSTGRES_PASSWORD=bedbasepassword -e POSTGRES_USER=postgres -e POSTGRES_DB=postgres -v postgres-data:/var/lib/postgresql/data postgres:13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above command might add environment variables, if it didn't happen run this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "export DB_HOST_URL='localhost'\n",
    "export POSTGRES_PORT=5432\n",
    "export POSTGRES_PASSWORD='bedbasepassword'\n",
    "export POSTGRES_USER='postgres'\n",
    "export POSTGRES_DB='postgres'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run bedstat  on the demo PEP\n",
    "To run `bedstat` and the other required pipelines in this tutorial, we will rely on the pipeline submission engine [looper](http://looper.databio.org/en/latest/), which can be installed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: looper in /home/bnt4me/.local/lib/python3.8/site-packages (1.3.1)\n",
      "Requirement already satisfied: pyyaml>=3.12 in /usr/lib/python3/dist-packages (from looper) (5.3.1)\n",
      "Requirement already satisfied: logmuse>=0.2.0 in /home/bnt4me/.local/lib/python3.8/site-packages (from looper) (0.2.7)\n",
      "Requirement already satisfied: jinja2 in /home/bnt4me/.local/lib/python3.8/site-packages (from looper) (3.0.2)\n",
      "Requirement already satisfied: pandas>=0.20.2 in /home/bnt4me/.local/lib/python3.8/site-packages (from looper) (1.3.4)\n",
      "Requirement already satisfied: eido>=0.1.3 in /home/bnt4me/.local/lib/python3.8/site-packages (from looper) (0.1.5)\n",
      "Requirement already satisfied: colorama>=0.3.9 in /usr/lib/python3/dist-packages (from looper) (0.4.3)\n",
      "Requirement already satisfied: peppy>=0.31.0 in /home/bnt4me/.local/lib/python3.8/site-packages (from looper) (0.31.1)\n",
      "Requirement already satisfied: attmap>=0.12.7 in /home/bnt4me/.local/lib/python3.8/site-packages (from looper) (0.13.0)\n",
      "Requirement already satisfied: divvy>=0.5.0 in /home/bnt4me/.local/lib/python3.8/site-packages (from looper) (0.5.0)\n",
      "Requirement already satisfied: ubiquerg>=0.5.2 in /home/bnt4me/.local/lib/python3.8/site-packages (from looper) (0.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/bnt4me/.local/lib/python3.8/site-packages (from jinja2->looper) (2.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/lib/python3/dist-packages (from pandas>=0.20.2->looper) (2.7.3)\n",
      "Requirement already satisfied: numpy>=1.17.3; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in /home/bnt4me/.local/lib/python3.8/site-packages (from pandas>=0.20.2->looper) (1.21.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas>=0.20.2->looper) (2019.3)\n",
      "Requirement already satisfied: jsonschema>=3.0.1 in /home/bnt4me/.local/lib/python3.8/site-packages (from eido>=0.1.3->looper) (4.1.0)\n",
      "Requirement already satisfied: yacman>=0.5.0 in /home/bnt4me/.local/lib/python3.8/site-packages (from divvy>=0.5.0->looper) (0.8.3)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/bnt4me/.local/lib/python3.8/site-packages (from jsonschema>=3.0.1->eido>=0.1.3->looper) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/bnt4me/.local/lib/python3.8/site-packages (from jsonschema>=3.0.1->eido>=0.1.3->looper) (21.2.0)\n",
      "Requirement already satisfied: oyaml in /home/bnt4me/.local/lib/python3.8/site-packages (from yacman>=0.5.0->divvy>=0.5.0->looper) (1.0)\n"
     ]
    }
   ],
   "source": [
    "pip install looper --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to establish a modular connection between a project and a pipeline, we'll need to create a [pipeline interface](http://looper.databio.org/en/latest/linking-a-pipeline/) file, which tells looper how to run the pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline_name: BEDSTAT\n",
      "pipeline_type: sample\n",
      "var_templates:\n",
      "  path: \"{looper.piface_dir}/pipeline/bedstat.py\"\n",
      "input_schema: http://schema.databio.org/pipelines/bedstat.yaml\n",
      "pre_submit:\n",
      "  python_functions:\n",
      "    - looper.write_sample_yaml\n",
      "command_template: >\n",
      "  {pipeline.var_templates.path}\n",
      "  --bedfile {sample.output_file_path}\n",
      "  --genome {sample.genome}\n",
      "  --sample-yaml {sample.yaml_file}\n",
      "  {% if sample.bedbase_config is defined %} --bedbase-config {sample.bedbase_config} {% endif %}\n",
      "  {% if sample.open_signal_matrix is defined %} --open-signal-matrix {sample.open_signal_matrix} {% endif %}\n",
      "  {% if sample.bigbed is defined %} --bigbed {sample.bigbed} {% endif %}\n"
     ]
    }
   ],
   "source": [
    "cat bedstat/pipeline_interface.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next open new terminal window and run this commands to create new schema:\n",
    "- 1) docker exec -it <em>container_id</em> bash\n",
    "- 2) psql -U postgres\n",
    "- 3) CREATE SCHEMA postgres;\n",
    "\n",
    "Next close postgres terminal and container terminal with command: \"exit\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have properly linked our project to the pipeline of interest, in this case` bedstat`, we simply need to point the `looper run` command our `PEP` config file. Additionally, if the bedbase configuration file location is not stored in the `$BEDBASE` variable, we can pass it to `looper` as an additional argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looper version: 1.3.1\n",
      "Command: run\n",
      "/home/bnt4me/.local/lib/python3.8/site-packages/divvy/compute.py:150: UserWarning: The '_file_path' property is deprecated and will be removed in a future release. Use ComputingConfiguration[\"__internal\"][\"_file_path\"] instead.\n",
      "  os.path.dirname(self._file_path),\n",
      "/home/bnt4me/.local/lib/python3.8/site-packages/divvy/compute.py:58: UserWarning: The '_file_path' property is deprecated and will be removed in a future release. Use ComputingConfiguration[\"__internal\"][\"_file_path\"] instead.\n",
      "  self.config_file = self._file_path\n",
      "Activating compute package 'local'\n",
      "\u001b[36m## [1 of 11] sample: bedbase_demo_db1; pipeline: BEDSTAT\u001b[0m\n",
      "Calling pre-submit function: looper.write_sample_yaml\n",
      "Writing script to /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedstat_output/bedstat_pipeline_logs/submission/BEDSTAT_bedbase_demo_db1.sub\n",
      "Job script (n=1; 0.00Gb): /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedstat_output/bedstat_pipeline_logs/submission/BEDSTAT_bedbase_demo_db1.sub\n",
      "\u001b[36m## [2 of 11] sample: bedbase_demo_db2; pipeline: BEDSTAT\u001b[0m\n",
      "Calling pre-submit function: looper.write_sample_yaml\n",
      "Writing script to /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedstat_output/bedstat_pipeline_logs/submission/BEDSTAT_bedbase_demo_db2.sub\n",
      "Job script (n=1; 0.00Gb): /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedstat_output/bedstat_pipeline_logs/submission/BEDSTAT_bedbase_demo_db2.sub\n",
      "\u001b[36m## [3 of 11] sample: bedbase_demo_db3; pipeline: BEDSTAT\u001b[0m\n",
      "Calling pre-submit function: looper.write_sample_yaml\n",
      "Writing script to /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedstat_output/bedstat_pipeline_logs/submission/BEDSTAT_bedbase_demo_db3.sub\n",
      "Job script (n=1; 0.00Gb): /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedstat_output/bedstat_pipeline_logs/submission/BEDSTAT_bedbase_demo_db3.sub\n",
      "\u001b[36m## [4 of 11] sample: bedbase_demo_db4; pipeline: BEDSTAT\u001b[0m\n",
      "Calling pre-submit function: looper.write_sample_yaml\n",
      "Writing script to /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedstat_output/bedstat_pipeline_logs/submission/BEDSTAT_bedbase_demo_db4.sub\n",
      "Job script (n=1; 0.01Gb): /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedstat_output/bedstat_pipeline_logs/submission/BEDSTAT_bedbase_demo_db4.sub\n",
      "\u001b[36m## [5 of 11] sample: bedbase_demo_db5; pipeline: BEDSTAT\u001b[0m\n",
      "Calling pre-submit function: looper.write_sample_yaml\n",
      "Writing script to /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedstat_output/bedstat_pipeline_logs/submission/BEDSTAT_bedbase_demo_db5.sub\n",
      "Job script (n=1; 0.01Gb): /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedstat_output/bedstat_pipeline_logs/submission/BEDSTAT_bedbase_demo_db5.sub\n",
      "\u001b[36m## [6 of 11] sample: bedbase_demo_db6; pipeline: BEDSTAT\u001b[0m\n",
      "Calling pre-submit function: looper.write_sample_yaml\n",
      "Writing script to /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedstat_output/bedstat_pipeline_logs/submission/BEDSTAT_bedbase_demo_db6.sub\n",
      "Job script (n=1; 0.00Gb): /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedstat_output/bedstat_pipeline_logs/submission/BEDSTAT_bedbase_demo_db6.sub\n",
      "\u001b[36m## [7 of 11] sample: bedbase_demo_db7; pipeline: BEDSTAT\u001b[0m\n",
      "Calling pre-submit function: looper.write_sample_yaml\n",
      "Writing script to /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedstat_output/bedstat_pipeline_logs/submission/BEDSTAT_bedbase_demo_db7.sub\n",
      "Job script (n=1; 0.00Gb): /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedstat_output/bedstat_pipeline_logs/submission/BEDSTAT_bedbase_demo_db7.sub\n",
      "\u001b[36m## [8 of 11] sample: bedbase_demo_db8; pipeline: BEDSTAT\u001b[0m\n",
      "Calling pre-submit function: looper.write_sample_yaml\n",
      "Writing script to /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedstat_output/bedstat_pipeline_logs/submission/BEDSTAT_bedbase_demo_db8.sub\n",
      "Job script (n=1; 0.01Gb): /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedstat_output/bedstat_pipeline_logs/submission/BEDSTAT_bedbase_demo_db8.sub\n",
      "\u001b[36m## [9 of 11] sample: bedhost_demo_db9; pipeline: BEDSTAT\u001b[0m\n",
      "Calling pre-submit function: looper.write_sample_yaml\n",
      "Writing script to /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedstat_output/bedstat_pipeline_logs/submission/BEDSTAT_bedhost_demo_db9.sub\n",
      "Job script (n=1; 0.01Gb): /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedstat_output/bedstat_pipeline_logs/submission/BEDSTAT_bedhost_demo_db9.sub\n",
      "\u001b[36m## [10 of 11] sample: bedbase_demo_db10; pipeline: BEDSTAT\u001b[0m\n",
      "Calling pre-submit function: looper.write_sample_yaml\n",
      "Writing script to /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedstat_output/bedstat_pipeline_logs/submission/BEDSTAT_bedbase_demo_db10.sub\n",
      "Job script (n=1; 0.01Gb): /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedstat_output/bedstat_pipeline_logs/submission/BEDSTAT_bedbase_demo_db10.sub\n",
      "\u001b[36m## [11 of 11] sample: bedbase_demo_db11; pipeline: BEDSTAT\u001b[0m\n",
      "Calling pre-submit function: looper.write_sample_yaml\n",
      "Writing script to /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedstat_output/bedstat_pipeline_logs/submission/BEDSTAT_bedbase_demo_db11.sub\n",
      "Job script (n=1; 0.01Gb): /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedstat_output/bedstat_pipeline_logs/submission/BEDSTAT_bedbase_demo_db11.sub\n",
      "\n",
      "Looper finished\n",
      "Samples valid for job generation: 11 of 11\n",
      "Commands submitted: 11 of 11\n",
      "Jobs submitted: 11\n"
     ]
    }
   ],
   "source": [
    "looper run bedbase/tutorial_files/PEPs/bedstat_config.yaml --package local \\\n",
    "--command-extra=\"-R\" > outputs/bedstat_output/bedstat_pipeline_logs/looper_logs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is an error: \"ImportError: cannot import name 'get_logger' from 'peppy.utils'\": reinstall looper\n",
    "\n",
    "To see if bedstats have been created successfully go to the looper logs, and see if there is no errors. Path to the looper log file is: \"bedbase_tutorial/outputs/bedstat_output/bedstat_pipeline_logs/looper_logs.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for informative purposes, we can inspect how `bedstat` operates on each bedfile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute node: cphg-Precision-5560\n",
      "Start time: 2021-11-11 12:13:52\n",
      "### Pipeline run code and environment:\n",
      "\n",
      "*              Command:  `/home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/bedstat/pipeline/bedstat.py --bedfile /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/bed_files/GSE105587_ENCFF018NNF_conservative_idr_thresholded_peaks_GRCh38.bed.gz --genome hg38 --sample-yaml /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedstat_output/bedstat_pipeline_logs/submission/bedbase_demo_db1_sample.yaml --bedbase-config /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/bedbase/tutorial_files/bedbase_configuration_compose.yaml --open-signal-matrix /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/openSignalMatrix_hg38_percentile99_01_quantNormalized_round4d.txt.gz --bigbed /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/bigbed_files -R`\n",
      "*         Compute host:  cphg-Precision-5560\n",
      "*          Working dir:  /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial\n",
      "*            Outfolder:  /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedstat_output/78c0e4753d04b238fc07e4ebe5a02984/\n",
      "*  Pipeline started at:   (11-11 12:13:53) elapsed: 0.0 _TIME_\n",
      "\n"
     ]
    }
   ],
   "source": [
    "head outputs/bedstat_output/bedstat_pipeline_logs/looper_logs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the previous steps have been executed, our bedfiles should be available for query on our local Elasticsearch cluster. Files can be queried using the `bedbuncher` pipeline described in the below section. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. BEDBUNCHER: Create bedsets and their respective statistics \n",
    "\n",
    "### Create a new PEP describing the bedset name and specific JSON query \n",
    "\n",
    "Now that we've processed several individual BED files, we'll turn to the next task: grouping them together into collections of BED files, which we call *bedsets*. For this, we use the `bedbuncher` pipeline, which produces outputs for each bedset, such as a bedset PEP, bedset-level statistics and plots, and an `IGD` database. To run `bedbuncher`, we will need another PEP describing each bedset. Though the annotation sheet below specifies attributes for one bedset, you can create as many as you wish using additional rows. For each bedset, you need to provide the query to retrieve certain collection BED files. \n",
    "\n",
    "The following example PEP shows the attributes we need to provide for each bedset and the config.yaml file that will grab the files needed to run `bedbuncher`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_name,bedset_name,genome,query,operator,query_val,bbconfig_name,bedbase_config\n",
      "sample1,bedsetOver1kRegions,hg38,'regions_no',gt,\"\"\"1000\"\"\",bedbase_configuration_compose,source1\n",
      "sample2,bedsetOver50GCContent,hg38,'gc_content',gt,\"\"\"0.5\"\"\",bedbase_configuration_compose,source1\n",
      "sample3,bedsetUnder500MeanWidth,hg38,'mean_region_width',lt,\"\"\"500\"\"\",bedbase_configuration_compose,source1\n",
      "sample4,bedsetTestSelectCellType,hg38,\"\"\"other::text~~:str_1 or other::text~~:str_2\"\"\",\"\"\"str_1,str_2\"\"\",\"\"\"%GM12878%,%HEK293%\"\"\",bedbase_configuration_compose,source1\n",
      "sample5,bedsetTestSelectGenome,hg38,\"\"\"name=:name_1 or name=:name_2\"\"\",\"\"\"name_1,name_2\"\"\",\"\"\"GSE105587_ENCFF018NNF_conservative_idr_thresholded_peaks_GRCh38,GSE91663_ENCFF553KIK_optimal_idr_thresholded_peaks_GRCh38\"\"\",bedbase_configuration_compose,source1\n",
      "sample6,bedsetTestCellType,hg38,\"\"\"other\"\"\",contains,\"\"\"\"\"{\\\"\"cell_type\\\"\":\\ \\\"\"K562\\\"\"}\"\"\"\"\",bedbase_configuration_compose,source1\n",
      "sample7,bedsetTestSpace,hg38,\"\"\"other\"\"\",contains,\"\"\"\"\"{\\\"\"description\\\"\":\\ \\\"\"IKZF1\\ ChIP-seq\\ on\\ human\\ GM12878\\\"\"}\"\"\"\"\",bedbase_configuration_compose,source1\n",
      "sample8,bedsetTestsSpaceMult,hg38,\"\"\"other::text~~:str_1 or other::text~~:str_2\"\"\",\"\"\"str_1,str_2\"\"\",\"\"\"%IKZF1 ChIP-seq on human GM12878%,%ZEB2 ChIP-seq on human K562 (ENCODE)%\"\"\",bedbase_configuration_compose,source1\n",
      "sample9,bedsetTestSpace2,hg38,\"\"\"other\"\"\",contains,\"\"\"\"\"{\\\"\"description\\\"\":\\ \\\"\"HEK293\\ cell\\ line\\ stably\\ expressing\\ N-terminal\\ tagged\\ eGFP-GLI2\\ under\\ the\\ control\\ of\\ a\\ CMV\\ promoter\\\"\"}\"\"\"\"\",bedbase_configuration_compose,source1\n",
      "sample10,bedsetTestsSpaceMult2,hg38,\"\"\"other::text~~:str_1 or other::text~~:str_2\"\"\",\"\"\"str_1,str_2\"\"\",\"\"\"%ZEB2 ChIP-seq on human K562 (ENCODE)%,%HEK293 cell line stably expressing N-terminal tagged eGFP-GLI2 under the control of a CMV promoter %\"\"\",bedbase_configuration_compose,source1\n"
     ]
    }
   ],
   "source": [
    "cat bedbase/tutorial_files/PEPs/bedbuncher_query.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pep_version: 2.0.0\n",
      "sample_table: bedbuncher_query.csv\n",
      "\n",
      "looper:\n",
      "    output_dir: $BBTUTORIAL/outputs/bedbuncher_output/bedbuncher_pipeline_logs\n",
      "    piface_dir: $BBTUTORIAL/bedbuncher\n",
      "\n",
      "sample_modifiers:\n",
      "  append:\n",
      "    pipeline_interfaces: $BBTUTORIAL/bedbuncher/pipeline_interface.yaml \n",
      "  derive:\n",
      "    attributes: [bedbase_config]\n",
      "    sources:\n",
      "      source1: $BBTUTORIAL/bedbase/tutorial_files/{bbconfig_name}.yaml\n"
     ]
    }
   ],
   "source": [
    "cat bedbase/tutorial_files/PEPs/bedbuncher_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running `bedbuncher` with arguments defined in the example PEP above will result in a bedset with bedfiles that consist of at least 1000 regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create outputs directory and install bedbuncher command line dependencies\n",
    "\n",
    "We need a folder where we can store bedset related outputs. Though not required, we'll also create a directory where we can store the `bedbuncher` pipeline logs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p outputs/bedbuncher_output/bedbuncher_pipeline_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the feats of `bedbuncher` includes [IGD](https://github.com/databio/IGD) database creation from the files in the bedset. `IGD` can be installed by cloning the repository from github, executing the make file to create the binary, and pointing the binary location with the `$PATH` environment variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'IGD'...\n",
      "remote: Enumerating objects: 1297, done.\u001b[K\n",
      "remote: Counting objects: 100% (67/67), done.\u001b[K\n",
      "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
      "remote: Total 1297 (delta 35), reused 40 (delta 17), pack-reused 1230\u001b[K\n",
      "Receiving objects: 100% (1297/1297), 949.45 KiB | 8.55 MiB/s, done.\n",
      "Resolving deltas: 100% (804/804), done.\n"
     ]
    }
   ],
   "source": [
    "git clone git@github.com:databio/IGD\n",
    "cd IGD\n",
    "make > igd_make_log.txt 2>&1\n",
    "cd ..\n",
    "\n",
    "export PATH=$BBTUTORIAL/IGD/bin/:$PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run bedbuncher using Looper \n",
    "\n",
    "Once we have cloned the `bedbuncher` repository, set our local Elasticsearch cluster and created the `iGD` binary, we can run the pipeline by pointing `looper run` to the appropriate `PEP` config file. As mentioned earlier, if the path to the bedbase configuration file has been stored in the `$BEDBASE` environment variable, it's not neccesary to pass the `--bedbase-config` argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looper version: 1.3.1\n",
      "Command: run\n",
      "/home/bnt4me/.local/lib/python3.8/site-packages/divvy/compute.py:150: UserWarning: The '_file_path' property is deprecated and will be removed in a future release. Use ComputingConfiguration[\"__internal\"][\"_file_path\"] instead.\n",
      "  os.path.dirname(self._file_path),\n",
      "/home/bnt4me/.local/lib/python3.8/site-packages/divvy/compute.py:58: UserWarning: The '_file_path' property is deprecated and will be removed in a future release. Use ComputingConfiguration[\"__internal\"][\"_file_path\"] instead.\n",
      "  self.config_file = self._file_path\n",
      "Activating compute package 'local'\n",
      "\u001b[36m## [1 of 10] sample: sample1; pipeline: BEDBUNCHER\u001b[0m\n",
      "Writing script to /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedbuncher_output/bedbuncher_pipeline_logs/submission/BEDBUNCHER_sample1.sub\n",
      "Job script (n=1; 0.00Gb): /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedbuncher_output/bedbuncher_pipeline_logs/submission/BEDBUNCHER_sample1.sub\n",
      "\u001b[36m## [2 of 10] sample: sample2; pipeline: BEDBUNCHER\u001b[0m\n",
      "Writing script to /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedbuncher_output/bedbuncher_pipeline_logs/submission/BEDBUNCHER_sample2.sub\n",
      "Job script (n=1; 0.00Gb): /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedbuncher_output/bedbuncher_pipeline_logs/submission/BEDBUNCHER_sample2.sub\n",
      "\u001b[36m## [3 of 10] sample: sample3; pipeline: BEDBUNCHER\u001b[0m\n",
      "Writing script to /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedbuncher_output/bedbuncher_pipeline_logs/submission/BEDBUNCHER_sample3.sub\n",
      "Job script (n=1; 0.00Gb): /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedbuncher_output/bedbuncher_pipeline_logs/submission/BEDBUNCHER_sample3.sub\n",
      "\u001b[36m## [4 of 10] sample: sample4; pipeline: BEDBUNCHER\u001b[0m\n",
      "Writing script to /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedbuncher_output/bedbuncher_pipeline_logs/submission/BEDBUNCHER_sample4.sub\n",
      "Job script (n=1; 0.00Gb): /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedbuncher_output/bedbuncher_pipeline_logs/submission/BEDBUNCHER_sample4.sub\n",
      "\u001b[36m## [5 of 10] sample: sample5; pipeline: BEDBUNCHER\u001b[0m\n",
      "Writing script to /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedbuncher_output/bedbuncher_pipeline_logs/submission/BEDBUNCHER_sample5.sub\n",
      "Job script (n=1; 0.00Gb): /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedbuncher_output/bedbuncher_pipeline_logs/submission/BEDBUNCHER_sample5.sub\n",
      "\u001b[36m## [6 of 10] sample: sample6; pipeline: BEDBUNCHER\u001b[0m\n",
      "Writing script to /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedbuncher_output/bedbuncher_pipeline_logs/submission/BEDBUNCHER_sample6.sub\n",
      "Job script (n=1; 0.00Gb): /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedbuncher_output/bedbuncher_pipeline_logs/submission/BEDBUNCHER_sample6.sub\n",
      "\u001b[36m## [7 of 10] sample: sample7; pipeline: BEDBUNCHER\u001b[0m\n",
      "Writing script to /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedbuncher_output/bedbuncher_pipeline_logs/submission/BEDBUNCHER_sample7.sub\n",
      "Job script (n=1; 0.00Gb): /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedbuncher_output/bedbuncher_pipeline_logs/submission/BEDBUNCHER_sample7.sub\n",
      "\u001b[36m## [8 of 10] sample: sample8; pipeline: BEDBUNCHER\u001b[0m\n",
      "Writing script to /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedbuncher_output/bedbuncher_pipeline_logs/submission/BEDBUNCHER_sample8.sub\n",
      "Job script (n=1; 0.00Gb): /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedbuncher_output/bedbuncher_pipeline_logs/submission/BEDBUNCHER_sample8.sub\n",
      "\u001b[36m## [9 of 10] sample: sample9; pipeline: BEDBUNCHER\u001b[0m\n",
      "Writing script to /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedbuncher_output/bedbuncher_pipeline_logs/submission/BEDBUNCHER_sample9.sub\n",
      "Job script (n=1; 0.00Gb): /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedbuncher_output/bedbuncher_pipeline_logs/submission/BEDBUNCHER_sample9.sub\n",
      "\u001b[36m## [10 of 10] sample: sample10; pipeline: BEDBUNCHER\u001b[0m\n",
      "Writing script to /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedbuncher_output/bedbuncher_pipeline_logs/submission/BEDBUNCHER_sample10.sub\n",
      "Job script (n=1; 0.00Gb): /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/outputs/bedbuncher_output/bedbuncher_pipeline_logs/submission/BEDBUNCHER_sample10.sub\n",
      "\n",
      "Looper finished\n",
      "Samples valid for job generation: 10 of 10\n",
      "Commands submitted: 10 of 10\n",
      "Jobs submitted: 10\n"
     ]
    }
   ],
   "source": [
    "looper run  bedbase/tutorial_files/PEPs/bedbuncher_config.yaml  --package local \\\n",
    "--command-extra=\"-R\" > outputs/bedbuncher_output/bedbuncher_pipeline_logs/looper_logs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. BEDHOST:  Serve BED files and API to explore pipeline outputs\n",
    "\n",
    "The last part of the tutorial consists on running a local instance of `bedhost` (a REST API for `bedstat` and `bedbuncher` produced outputs) in order to explore plots, statistics and download pipeline outputs. \n",
    "To run `bedhost`, frist use `bedhost-ui` to built the bedhost user interface with React."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m @babel/plugin-bugfix-v8-spread-parameters-in-optional-chaining@7.16.0 requires a peer of @babel/core@^7.13.0 but none is installed. You must install peer dependencies yourself.\n",
      "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m bootstrap@4.6.0 requires a peer of popper.js@^1.16.1 but none is installed. You must install peer dependencies yourself.\n",
      "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m material-table@1.69.1 requires a peer of react@^16.8.4 but none is installed. You must install peer dependencies yourself.\n",
      "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m material-table@1.69.1 requires a peer of react-dom@^16.8.4 but none is installed. You must install peer dependencies yourself.\n",
      "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m react-resize-detector@2.3.0 requires a peer of react@^0.14.7 || ^15.0.0 || ^16.0.0 but none is installed. You must install peer dependencies yourself.\n",
      "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m react-smooth@1.0.5 requires a peer of react@^15.0.0 || ^16.0.0 but none is installed. You must install peer dependencies yourself.\n",
      "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m react-smooth@1.0.5 requires a peer of react-dom@^15.0.0 || ^16.0.0 but none is installed. You must install peer dependencies yourself.\n",
      "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m recharts@1.8.5 requires a peer of react@^15.0.0 || ^16.0.0 but none is installed. You must install peer dependencies yourself.\n",
      "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m recharts@1.8.5 requires a peer of react-dom@^15.0.0 || ^16.0.0 but none is installed. You must install peer dependencies yourself.\n",
      "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m tsutils@3.21.0 requires a peer of typescript@>=2.8.0 || >= 3.2.0-dev || >= 3.3.0-dev || >= 3.4.0-dev || >= 3.5.0-dev || >= 3.6.0-dev || >= 3.6.0-beta || >= 3.7.0-dev || >= 3.7.0-beta but none is installed. You must install peer dependencies yourself.\n",
      "\u001b[0m\n",
      "\u001b[K\u001b[?25haudited 2222 packages in 5.187s prepare:bedhost-ui: \u001b[30;43mWARN\u001b[0m tsutils@3.21.0 requires a peer\u001b[0m\u001b[K[0m\u001b[K\n",
      "\n",
      "162 packages are looking for funding\n",
      "  run `npm fund` for details\n",
      "\n",
      "found \u001b[91m29\u001b[0m vulnerabilities (9 \u001b[93mmoderate\u001b[0m, 19 \u001b[91mhigh\u001b[0m, 1 \u001b[95mcritical\u001b[0m)\n",
      "  run `npm audit fix` to fix them, or `npm audit` for details\n",
      "\u001b[K\u001b[?25h7m         \u001b[27m\u001b[90m.........\u001b[0m] | prepare:bedhost-ui: \u001b[32;40mtiming\u001b[0m \u001b[35maudit body\u001b[0m Completed in 2ms\u001b[0m\u001b[K\n",
      "> bedhost-ui@0.2.0 build /home/bnt4me/Virginia/bed_maker_new/bedbase_tutorial/bedhost-ui\n",
      "> react-scripts build\n",
      "\n",
      "Creating an optimized production build...\n",
      "\u001b[32mCompiled successfully.\u001b[39m\n",
      "\u001b[32m\u001b[39m\n",
      "File sizes after gzip:\n",
      "\n",
      "  626.16 KB (\u001b[33m+697 B\u001b[39m)  \u001b[2mbuild/static/js/\u001b[22m\u001b[36m2.3f5a2abd.chunk.js\u001b[39m\n",
      "  53.28 KB (\u001b[33m+32 B\u001b[39m)    \u001b[2mbuild/static/js/\u001b[22m\u001b[36m3.ab63ac01.chunk.js\u001b[39m\n",
      "  39.67 KB (\u001b[33m+569 B\u001b[39m)   \u001b[2mbuild/static/js/\u001b[22m\u001b[36m5.b133d99c.chunk.js\u001b[39m\n",
      "  22.6 KB (\u001b[32m-168 B\u001b[39m)    \u001b[2mbuild/static/css/\u001b[22m\u001b[36m2.1dd1e755.chunk.css\u001b[39m\n",
      "  14.14 KB (\u001b[33m+149 B\u001b[39m)   \u001b[2mbuild/static/js/\u001b[22m\u001b[36mmain.ace00c02.chunk.js\u001b[39m\n",
      "  7.03 KB (\u001b[33m+16 B\u001b[39m)     \u001b[2mbuild/static/js/\u001b[22m\u001b[36m4.b6abde7e.chunk.js\u001b[39m\n",
      "  2.13 KB (\u001b[33m+1 B\u001b[39m)      \u001b[2mbuild/static/css/\u001b[22m\u001b[36mmain.d57766bc.chunk.css\u001b[39m\n",
      "  1.19 KB (\u001b[33m+1 B\u001b[39m)      \u001b[2mbuild/static/js/\u001b[22m\u001b[36mruntime-main.690188d8.js\u001b[39m\n",
      "\n",
      "The project was built assuming it is hosted at \u001b[32m./ui/\u001b[39m.\n",
      "You can control this with the \u001b[32mhomepage\u001b[39m field in your \u001b[36mpackage.json\u001b[39m.\n",
      "\n",
      "The \u001b[36mbuild\u001b[39m folder is ready to be deployed.\n",
      "\n",
      "Find out more about deployment here:\n",
      "\n",
      "  \u001b[33mhttps://cra.link/deployment\u001b[39m\n",
      "\n",
      "'./build' -> '../bedhost/bedhost/static/bedhost-ui/build'\n",
      "'./build/.DS_Store' -> '../bedhost/bedhost/static/bedhost-ui/build/.DS_Store'\n",
      "'./build/bedbase_logo.svg' -> '../bedhost/bedhost/static/bedhost-ui/build/bedbase_logo.svg'\n",
      "'./build/favicon.ico' -> '../bedhost/bedhost/static/bedhost-ui/build/favicon.ico'\n",
      "'./build/manifest.json' -> '../bedhost/bedhost/static/bedhost-ui/build/manifest.json'\n",
      "'./build/robots.txt' -> '../bedhost/bedhost/static/bedhost-ui/build/robots.txt'\n",
      "'./build/workflow.svg' -> '../bedhost/bedhost/static/bedhost-ui/build/workflow.svg'\n",
      "'./build/static' -> '../bedhost/bedhost/static/bedhost-ui/build/static'\n",
      "'./build/static/css' -> '../bedhost/bedhost/static/bedhost-ui/build/static/css'\n",
      "'./build/static/css/main.d57766bc.chunk.css' -> '../bedhost/bedhost/static/bedhost-ui/build/static/css/main.d57766bc.chunk.css'\n",
      "'./build/static/css/main.d57766bc.chunk.css.map' -> '../bedhost/bedhost/static/bedhost-ui/build/static/css/main.d57766bc.chunk.css.map'\n",
      "'./build/static/css/2.1dd1e755.chunk.css.map' -> '../bedhost/bedhost/static/bedhost-ui/build/static/css/2.1dd1e755.chunk.css.map'\n",
      "'./build/static/css/2.1dd1e755.chunk.css' -> '../bedhost/bedhost/static/bedhost-ui/build/static/css/2.1dd1e755.chunk.css'\n",
      "'./build/static/js' -> '../bedhost/bedhost/static/bedhost-ui/build/static/js'\n",
      "'./build/static/js/3.ab63ac01.chunk.js' -> '../bedhost/bedhost/static/bedhost-ui/build/static/js/3.ab63ac01.chunk.js'\n",
      "'./build/static/js/2.3f5a2abd.chunk.js' -> '../bedhost/bedhost/static/bedhost-ui/build/static/js/2.3f5a2abd.chunk.js'\n",
      "'./build/static/js/5.b133d99c.chunk.js' -> '../bedhost/bedhost/static/bedhost-ui/build/static/js/5.b133d99c.chunk.js'\n",
      "'./build/static/js/runtime-main.690188d8.js' -> '../bedhost/bedhost/static/bedhost-ui/build/static/js/runtime-main.690188d8.js'\n",
      "'./build/static/js/3.ab63ac01.chunk.js.LICENSE.txt' -> '../bedhost/bedhost/static/bedhost-ui/build/static/js/3.ab63ac01.chunk.js.LICENSE.txt'\n",
      "'./build/static/js/2.3f5a2abd.chunk.js.LICENSE.txt' -> '../bedhost/bedhost/static/bedhost-ui/build/static/js/2.3f5a2abd.chunk.js.LICENSE.txt'\n",
      "'./build/static/js/main.ace00c02.chunk.js' -> '../bedhost/bedhost/static/bedhost-ui/build/static/js/main.ace00c02.chunk.js'\n",
      "'./build/static/js/4.b6abde7e.chunk.js.LICENSE.txt' -> '../bedhost/bedhost/static/bedhost-ui/build/static/js/4.b6abde7e.chunk.js.LICENSE.txt'\n",
      "'./build/static/js/5.b133d99c.chunk.js.LICENSE.txt' -> '../bedhost/bedhost/static/bedhost-ui/build/static/js/5.b133d99c.chunk.js.LICENSE.txt'\n",
      "'./build/static/js/main.ace00c02.chunk.js.map' -> '../bedhost/bedhost/static/bedhost-ui/build/static/js/main.ace00c02.chunk.js.map'\n",
      "'./build/static/js/4.b6abde7e.chunk.js' -> '../bedhost/bedhost/static/bedhost-ui/build/static/js/4.b6abde7e.chunk.js'\n",
      "'./build/static/js/runtime-main.690188d8.js.map' -> '../bedhost/bedhost/static/bedhost-ui/build/static/js/runtime-main.690188d8.js.map'\n",
      "'./build/static/js/2.3f5a2abd.chunk.js.map' -> '../bedhost/bedhost/static/bedhost-ui/build/static/js/2.3f5a2abd.chunk.js.map'\n",
      "'./build/static/js/3.ab63ac01.chunk.js.map' -> '../bedhost/bedhost/static/bedhost-ui/build/static/js/3.ab63ac01.chunk.js.map'\n",
      "'./build/static/js/4.b6abde7e.chunk.js.map' -> '../bedhost/bedhost/static/bedhost-ui/build/static/js/4.b6abde7e.chunk.js.map'\n",
      "'./build/static/js/5.b133d99c.chunk.js.map' -> '../bedhost/bedhost/static/bedhost-ui/build/static/js/5.b133d99c.chunk.js.map'\n",
      "'./build/index.html' -> '../bedhost/bedhost/static/bedhost-ui/build/index.html'\n",
      "'./build/asset-manifest.json' -> '../bedhost/bedhost/static/bedhost-ui/build/asset-manifest.json'\n"
     ]
    }
   ],
   "source": [
    "cd bedhost-ui\n",
    "# Install node modules defined in package.json\n",
    "npm install \n",
    "# Build the app for production to the ./build folder\n",
    "npm run build\n",
    "# copy the contents of the ./build directory to bedhost/bedhost/static/bedhost-ui\n",
    "cp -avr ./build ../bedhost/bedhost/static/bedhost-ui\n",
    "\n",
    "cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run `bedhost`, we'll pip install the package from the previously cloned repository:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install bedhost/. --user > bedhost_log.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path:\n",
      "  pipeline_output_path: $BEDBASE_DATA_PATH_HOST/outputs\n",
      "  bedstat_dir: bedstat_output\n",
      "  bedbuncher_dir: bedbuncher_output\n",
      "  remote_url_base: null\n",
      "database:\n",
      "  host: $DB_HOST_URL\n",
      "  port: $POSTGRES_PORT\n",
      "  password: $POSTGRES_PASSWORD\n",
      "  user: $POSTGRES_USER\n",
      "  name: $POSTGRES_DB\n",
      "  dialect: postgresql\n",
      "  driver: psycopg2\n",
      "server:\n",
      "  host: 0.0.0.0\n",
      "  port: 8000\n"
     ]
    }
   ],
   "source": [
    "cat $BBTUTORIAL/bedbase/tutorial_files/bedbase_configuration_compose.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd bedhost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start `bedhost`, we simply need to run the following command passing the location of the bedbase configuration file to the `-c` flag.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving data for columns: ['md5sum']\n",
      "Serving data for columns: ['md5sum']\n",
      "Generating GraphQL schema\n",
      "running bedhost app\n",
      "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m270433\u001b[0m]\n",
      "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
      "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
      "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:8000\u001b[0m (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "bedhost serve -c  $BBTUTORIAL/bedbase/tutorial_files/bedbase_configuration_compose.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have stored the path to the bedbase config in the environment variable `$BEDBASE` (suggested), it's not neccesary to use said flag. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedhost serve "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `bedhost` API can be opened in the url [http://0.0.0.0:8000](http://0.0.0.0:8000). We can now explore the plots and statistics generated by the `bedstat` and `bedbuncher` pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## or optionally run BEDHOST using containers\n",
    "\n",
    "Alternatively, you can run the application inside a container.\n",
    "\n",
    "For that we'll use [docker compose](https://docs.docker.com/compose/), a tool that makes running multi-contaier Docker applications possible. The `docker-compose.yaml` file defines two services: \n",
    "- `fastapi-api`: runs the fastAPI server \n",
    "- `postgres-db`: runs the PostgeSQL database used by the server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd $BBTUTORIAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `BEDBASE_DATA_PATH_HOST` environment variable to point to the host directory with the pipeline results that will be mounted in the container as a volume. \n",
    "\n",
    "The environment variables are passed to the container via `.env` file, which the `docker-compose.yaml` points to for each service. Additionally, you can just export the environment variables before issuing the `docker-compose` command.\n",
    "When you set the same environment variable in multiple files, here’s the priority used by Compose to choose which value to use:\n",
    "\n",
    "1. Compose file\n",
    "2. Shell environment variables\n",
    "3. Environment file\n",
    "4. Dockerfile\n",
    "4. Variable is not defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd bedhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "export DB_HOST_URL=postgres-db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker-compose up "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "329.797px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
